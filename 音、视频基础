##音、视频基础
@(Markdown)

[toc]

对媒体内容进行数字化主要有两种方式，第一种称为时间采样，捕捉一个信号在一定周期内的变化。比如使用 iPhone 记录一段音频，在录制期间所有音高和声调变化都会被捕捉下来；第二种是空间采样，一般用在图片或其他可视化媒体内容数字化过程中，空间采样包含对一幅图片在一定分辨率下捕捉其亮度和色度，进而创建由该图片的像素点数据所构成的数字化结果。

###视频
视频文件由一系列称为“帧”的图片组成，在视频文件的时间轴上每一帧表示一个场景。视频文件每一秒所展现的帧数称为视频的帧率，用 *FPS* 作为单位
####YUV
视频数据通常使用 $Y'C_bC_{r'}$ 颜色模式，也常称为 $YUV$，*Y* 表示像素亮度通道，*UV* 表示像素色彩通道。由于眼镜对亮度的敏感度高于颜色，可以减少像素中的颜色信息而不至于图片的质量受损。这个减少颜色数据的过程称为 **色彩二次抽样**。
摄像头或者其他视频设备硬件、软件提到的4:4:4，4:2:2，4:2:0，这些值的含义就是所使用的色彩二次抽样参数。这个格式写作 *J:a:b* 
- J: 关联色块中所包含的像素数
- a: 第一行每个J像素的色度像素个数
- b: 第二行每个J像素的附加像素个数

(1) YUV 4:4:4
原始数据：[Y0, U0, V0], [Y1, U1, V1], [Y2, U2, V2], [Y3, U3, V3]
存放码流：Y0 U0 V0 Y1 U1 V1 Y2 V2 U2 Y3 U3 V3
解码后：[Y0, U0, V0], [Y1, U1, V1], [Y2, U2, V2], [Y3, U3, V3]

(2) YUV 4:2:2
原始数据：[Y0, U0, V0], [Y1, U1, V1], [Y2, U2, V2], [Y3, U3, V3]
存放码流：Y0 U0  Y1 V1 Y2 U2 Y3 V3
解码后：[Y0, U0, V1], [Y1, U0, V1], [Y2, U2, V3], [Y3, U2, V3]

(3) YUV 4:2:0
原始数据：
[Y0, U0, V0], [Y1, U1, V1], [Y2, U2, V2], [Y3, U3, V3],
[Y5, U5, V5], [Y5, U6, V6], [Y7, U7, V7], [Y8, U8, V8]
存放码流：
Y0 U0 Y1 Y2 U2 Y3
Y5 V5 Y6 Y7 V7 V8
解码后：
[Y0, U0, V5], [Y1, U0, V5], [Y2, U2, V7], [Y3, U2, V7],
[Y5, U0, V5], [Y6, U0, V5], [Y7, U2, V7], [Y8, U2, V7]

*iOS* 设备所使用的参数为 4:2:0 。

####H.264 
*H.264* 规范是 *MPEG-4* 的一部分
*H.264* 与其他形式的 *MPEG* 压缩一样，通过以下两个维度缩小视频文件尺寸
- 空间：压缩独立视频帧，称为帧内压缩
- 时间：通过以组为单位视频帧压缩冗余数据，称为帧间压缩

帧内压缩通过消除包含在每个独立视频帧内的色彩及结构中的冗余信息来进行压缩，类似于 *JEPG*。通过这一过程创建的帧称为 *I-frames* 
帧间压缩中，很多帧被组合在一起作为一个 *GOP*，对于 *GOP* 所存在的时间维度冗余可以被消除
- *I-frames*：这些帧都是单独的帧或关键帧，包含创建完整图片需要的所有数据。每个 *GOP* 正好有一个 *I-frames* ，它的尺寸最大，解压最快
- *P-frames*：又称为预测帧，基于前一个 *I-frames* 或者 *P-frames* 的可预测图片进行编码得到
-  *B-frames*：又称为双向帧，基于前一个和后一个 *I-frames* 或 *P-frames* 编码得到的帧，所需存储空间最小，解压最消耗资源

###音频
音频数字化的过程包含一个编码方法， 称为线性脉冲编码调制 *LPCM* 。这个过程采样或测量一个固定的音频信号，过程的周期率被称为采样率。采样率一般需要达到音频频率的两倍才能得到比较好的数字化效果。CD录制的音频采样率为 44.1kHz。
数字音频采样的另一个重要方面是我们能够捕捉到什么精度的音频样本。用于保存样本的字节数定义了在线性维度上可行的离散度，这个信息被称为音频的**位元深度**，CD音质的位元深度为16，可以达到65536个离散级别。

####AAC
// TODO

###容器格式
一个多媒体文件通常包含视频、音频、字幕、章节信息等，因此需要一个规范用于确定文件结构，这种规范称为容器格式。
常见的有 FLV、QuickTime、MPEG-4 等